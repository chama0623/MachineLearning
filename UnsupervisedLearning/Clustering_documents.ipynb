{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# クラスタリングを用いて, 関連する文書を見つける\n",
    "\n",
    "Q&Aサイトにおいて, ユーザーが入力したQuestionに関連するQuestionを提示する問題について考える.\n",
    "\n",
    "Reference : 実践 機械学習システム Willi Richert, Luis Pedro Coelho著"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"./textdata/\"\n",
    "posts = [open(os.path.join(DIR,f)).read() for f in os.listdir(DIR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a toy post about machine learning. Actually, it contains not much interesting stuff.',\n",
       " 'Imaging databases provide storage capabilities.',\n",
       " 'Most imaging databases save images permanently.',\n",
       " 'Imaging databases store data.',\n",
       " 'Imaging databases store data. Imaging databases store data. Imaging databases store data.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoWの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples 5 , features 25\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=1) # 1回のみ出現する単語を除く\n",
    "X_train = vectorizer.fit_transform(posts)\n",
    "num_samples,num_features = X_train.shape\n",
    "print(\"samples %d , features %d\" %(num_samples,num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['about',\n",
       " 'actually',\n",
       " 'capabilities',\n",
       " 'contains',\n",
       " 'data',\n",
       " 'databases',\n",
       " 'images',\n",
       " 'imaging',\n",
       " 'interesting',\n",
       " 'is',\n",
       " 'it',\n",
       " 'learning',\n",
       " 'machine',\n",
       " 'most',\n",
       " 'much',\n",
       " 'not',\n",
       " 'permanently',\n",
       " 'post',\n",
       " 'provide',\n",
       " 'save',\n",
       " 'storage',\n",
       " 'store',\n",
       " 'stuff',\n",
       " 'this',\n",
       " 'toy']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ユークリッド距離を用いた類似度の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_post = \"imaging databases\" # 新しい文書\n",
    "new_post_vec = vectorizer.transform([new_post])\n",
    "new_post_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_raw(v1,v2):\n",
    "    \"\"\"\n",
    "    ユークリッド距離を計算する関数\n",
    "    \"\"\"\n",
    "    delta = v1-v2\n",
    "    return sp.linalg.norm(delta.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Post 0 with dist=4.00: This is a toy post about machine learning. Actually, it contains not much interesting stuff.\n",
      "=== Post 1 with dist=1.73: Imaging databases provide storage capabilities.\n",
      "=== Post 2 with dist=2.00: Most imaging databases save images permanently.\n",
      "=== Post 3 with dist=1.41: Imaging databases store data.\n",
      "=== Post 4 with dist=5.10: Imaging databases store data. Imaging databases store data. Imaging databases store data.\n",
      "Best post is 3 with dist=1.41\n"
     ]
    }
   ],
   "source": [
    "best_doc = None\n",
    "best_dist = sys.maxsize # intの最大値を代入\n",
    "best_i = None\n",
    "\n",
    "# postに最も類似するtrainの文書を探索\n",
    "for i in range(0,num_samples):\n",
    "    post = posts[i]\n",
    "    if post ==new_post: # postとnew_postが一致していろとき, 処理をスキップ\n",
    "        continue\n",
    "    post_vec = X_train.getrow(i)\n",
    "    d = dist_raw(post_vec,new_post_vec)\n",
    "    print(\"=== Post %i with dist=%.2f: %s\" %(i,d,post))\n",
    "    if d<best_dist:\n",
    "        best_dist = d\n",
    "        best_i = i\n",
    "print(\"Best post is %i with dist=%.2f\" %(best_i,best_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文書3が最も類似している文章であるという結果がえられた. また, 文書4が最も類似していない文書であるという結果が得られた. しかし文書4は, 文書3を3回繰り返した文書であるから単語の出現回数だけを特徴量として用いるのは単純すぎると考えられる. そこで特徴量ベクトルを正規化する処理を行う."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_norm(v1,v2):\n",
    "    \"\"\"\n",
    "    ユークリッド距離を計算して正規化する関数\n",
    "    \"\"\"\n",
    "    v1_norm = v1/sp.linalg.norm(v1.toarray())\n",
    "    v2_norm = v2/sp.linalg.norm(v2.toarray())\n",
    "    delta = v1_norm-v2_norm\n",
    "    return sp.linalg.norm(delta.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Post 0 with dist=1.41: This is a toy post about machine learning. Actually, it contains not much interesting stuff.\n",
      "=== Post 1 with dist=0.86: Imaging databases provide storage capabilities.\n",
      "=== Post 2 with dist=0.92: Most imaging databases save images permanently.\n",
      "=== Post 3 with dist=0.77: Imaging databases store data.\n",
      "=== Post 4 with dist=0.77: Imaging databases store data. Imaging databases store data. Imaging databases store data.\n",
      "Best post is 3 with dist=0.77\n"
     ]
    }
   ],
   "source": [
    "best_doc = None\n",
    "best_dist = sys.maxsize # intの最大値を代入\n",
    "best_i = None\n",
    "\n",
    "# postに最も類似するtrainの文書を探索\n",
    "for i in range(0,num_samples):\n",
    "    post = posts[i]\n",
    "    if post ==new_post: # postとnew_postが一致していろとき, 処理をスキップ\n",
    "        continue\n",
    "    post_vec = X_train.getrow(i)\n",
    "    d = dist_norm(post_vec,new_post_vec)\n",
    "    print(\"=== Post %i with dist=%.2f: %s\" %(i,d,post))\n",
    "    if d<best_dist:\n",
    "        best_dist = d\n",
    "        best_i = i\n",
    "print(\"Best post is %i with dist=%.2f\" %(best_i,best_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正規化を行うことで, 文書3と文書4の類似度が同じになったことが読み取れる."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重要度の低い単語の除去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples 5 , features 18\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=1,stop_words=\"english\") # 1回のみ出現する単語を除く,英語のストップワード辞書を使用\n",
    "X_train = vectorizer.fit_transform(posts)\n",
    "num_samples,num_features = X_train.shape\n",
    "print(\"samples %d , features %d\" %(num_samples,num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actually',\n",
       " 'capabilities',\n",
       " 'contains',\n",
       " 'data',\n",
       " 'databases',\n",
       " 'images',\n",
       " 'imaging',\n",
       " 'interesting',\n",
       " 'learning',\n",
       " 'machine',\n",
       " 'permanently',\n",
       " 'post',\n",
       " 'provide',\n",
       " 'save',\n",
       " 'storage',\n",
       " 'store',\n",
       " 'stuff',\n",
       " 'toy']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_post = \"imaging databases\" # 新しい文書\n",
    "new_post_vec = vectorizer.transform([new_post])\n",
    "new_post_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Post 0 with dist=1.41: This is a toy post about machine learning. Actually, it contains not much interesting stuff.\n",
      "=== Post 1 with dist=0.86: Imaging databases provide storage capabilities.\n",
      "=== Post 2 with dist=0.86: Most imaging databases save images permanently.\n",
      "=== Post 3 with dist=0.77: Imaging databases store data.\n",
      "=== Post 4 with dist=0.77: Imaging databases store data. Imaging databases store data. Imaging databases store data.\n",
      "Best post is 3 with dist=0.77\n"
     ]
    }
   ],
   "source": [
    "best_doc = None\n",
    "best_dist = sys.maxsize # intの最大値を代入\n",
    "best_i = None\n",
    "\n",
    "# postに最も類似するtrainの文書を探索\n",
    "for i in range(0,num_samples):\n",
    "    post = posts[i]\n",
    "    if post ==new_post: # postとnew_postが一致していろとき, 処理をスキップ\n",
    "        continue\n",
    "    post_vec = X_train.getrow(i)\n",
    "    d = dist_norm(post_vec,new_post_vec)\n",
    "    print(\"=== Post %i with dist=%.2f: %s\" %(i,d,post))\n",
    "    if d<best_dist:\n",
    "        best_dist = d\n",
    "        best_i = i\n",
    "print(\"Best post is %i with dist=%.2f\" %(best_i,best_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stemming\n",
    "images, imagingの語幹を揃える処理を行う."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer,self).build_analyzer()\n",
    "        return lambda doc:(english_stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples 5 , features 17\n"
     ]
    }
   ],
   "source": [
    "english_stemmer = nltk.stem.SnowballStemmer(\"english\")\n",
    "vectorizer = StemmedCountVectorizer(min_df=1,stop_words=\"english\")\n",
    "X_train = vectorizer.fit_transform(posts)\n",
    "num_samples,num_features = X_train.shape\n",
    "print(\"samples %d , features %d\" %(num_samples,num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actual',\n",
       " 'capabl',\n",
       " 'contain',\n",
       " 'data',\n",
       " 'databas',\n",
       " 'imag',\n",
       " 'interest',\n",
       " 'learn',\n",
       " 'machin',\n",
       " 'perman',\n",
       " 'post',\n",
       " 'provid',\n",
       " 'save',\n",
       " 'storag',\n",
       " 'store',\n",
       " 'stuff',\n",
       " 'toy']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_post = \"imaging databases\" # 新しい文書\n",
    "new_post_vec = vectorizer.transform([new_post])\n",
    "new_post_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Post 0 with dist=1.41: This is a toy post about machine learning. Actually, it contains not much interesting stuff.\n",
      "=== Post 1 with dist=0.86: Imaging databases provide storage capabilities.\n",
      "=== Post 2 with dist=0.63: Most imaging databases save images permanently.\n",
      "=== Post 3 with dist=0.77: Imaging databases store data.\n",
      "=== Post 4 with dist=0.77: Imaging databases store data. Imaging databases store data. Imaging databases store data.\n",
      "Best post is 2 with dist=0.63\n"
     ]
    }
   ],
   "source": [
    "best_doc = None\n",
    "best_dist = sys.maxsize # intの最大値を代入\n",
    "best_i = None\n",
    "\n",
    "# postに最も類似するtrainの文書を探索\n",
    "for i in range(0,num_samples):\n",
    "    post = posts[i]\n",
    "    if post ==new_post: # postとnew_postが一致していろとき, 処理をスキップ\n",
    "        continue\n",
    "    post_vec = X_train.getrow(i)\n",
    "    d = dist_norm(post_vec,new_post_vec)\n",
    "    print(\"=== Post %i with dist=%.2f: %s\" %(i,d,post))\n",
    "    if d<best_dist:\n",
    "        best_dist = d\n",
    "        best_i = i\n",
    "print(\"Best post is %i with dist=%.2f\" %(best_i,best_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDFを用いる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(TfidfVectorizer,self).build_analyzer()\n",
    "        return lambda doc:(english_stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples 5 , features 17\n"
     ]
    }
   ],
   "source": [
    "vectorizer = StemmedTfidfVectorizer(min_df=1,stop_words=\"english\")\n",
    "X_train = vectorizer.fit_transform(posts)\n",
    "num_samples,num_features = X_train.shape\n",
    "print(\"samples %d , features %d\" %(num_samples,num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Post 0 with dist=1.41: This is a toy post about machine learning. Actually, it contains not much interesting stuff.\n",
      "=== Post 1 with dist=1.08: Imaging databases provide storage capabilities.\n",
      "=== Post 2 with dist=0.86: Most imaging databases save images permanently.\n",
      "=== Post 3 with dist=0.92: Imaging databases store data.\n",
      "=== Post 4 with dist=0.92: Imaging databases store data. Imaging databases store data. Imaging databases store data.\n",
      "Best post is 2 with dist=0.86\n"
     ]
    }
   ],
   "source": [
    "best_doc = None\n",
    "best_dist = sys.maxsize # intの最大値を代入\n",
    "best_i = None\n",
    "\n",
    "# postに最も類似するtrainの文書を探索\n",
    "for i in range(0,num_samples):\n",
    "    post = posts[i]\n",
    "    if post ==new_post: # postとnew_postが一致していろとき, 処理をスキップ\n",
    "        continue\n",
    "    post_vec = X_train.getrow(i)\n",
    "    d = dist_norm(post_vec,new_post_vec)\n",
    "    print(\"=== Post %i with dist=%.2f: %s\" %(i,d,post))\n",
    "    if d<best_dist:\n",
    "        best_dist = d\n",
    "        best_i = i\n",
    "print(\"Best post is %i with dist=%.2f\" %(best_i,best_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## newsデータを使用して関連文書を見つけるプログラムを実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "groups = ['comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware',\n",
    "          'comp.sys.mac.hardware', 'comp.windows.x', 'sci.space']\n",
    "train_data = sklearn.datasets.load_files(\"./20news-bydate-train\",categories=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3529"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples 3529 , features 4713\n"
     ]
    }
   ],
   "source": [
    "vectorizer = StemmedTfidfVectorizer(min_df=10,max_df=0.5,stop_words=\"english\",decode_error=\"ignore\") # 不適切な文字を無視する\n",
    "vectorized = vectorizer.fit_transform(train_data.data)\n",
    "num_samples,num_features = vectorized.shape\n",
    "print(\"samples %d , features %d\" %(num_samples,num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration 0, inertia 5923.803883312907\n",
      "Iteration 1, inertia 3207.479772762691\n",
      "Iteration 2, inertia 3170.175656054051\n",
      "Iteration 3, inertia 3151.09387971308\n",
      "Iteration 4, inertia 3139.2613820461893\n",
      "Iteration 5, inertia 3131.7715363446837\n",
      "Iteration 6, inertia 3128.3920958981525\n",
      "Iteration 7, inertia 3124.970058624086\n",
      "Iteration 8, inertia 3123.5550620211015\n",
      "Iteration 9, inertia 3122.466962700782\n",
      "Iteration 10, inertia 3121.746288937305\n",
      "Iteration 11, inertia 3121.1483608070535\n",
      "Iteration 12, inertia 3120.099768227793\n",
      "Iteration 13, inertia 3119.140247495304\n",
      "Iteration 14, inertia 3118.702072741001\n",
      "Iteration 15, inertia 3118.6756902346233\n",
      "Converged at iteration 15: strict convergence.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(init='random', n_clusters=50, n_init=1, verbose=1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_clusters=50\n",
    "model = KMeans(n_clusters=n_clusters,init=\"random\",n_init=1,verbose=1)\n",
    "model.fit(vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verboseで表示される数字は重心からインスタンスまでのユークリッド距離を総和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_post = \"Disk drive problem. Hi, I have a problem with my hard disk. After 1 year it is working only sporadically now. I tried to format it, but now it dosen't boot any more. Any ideas? Thanks.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_post_vec = vectorizer.transform([new_post])\n",
    "new_post_label = model.predict(new_post_vec)[0]\n",
    "similar_indices = (model.labels_ == new_post_label).nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    }
   ],
   "source": [
    "similar = []\n",
    "for i in similar_indices:\n",
    "    dist = sp.linalg.norm((new_post_vec-vectorized[i]).toarray())\n",
    "    similar.append((dist,dataset.data[i]))\n",
    "similar = sorted(similar)\n",
    "print(len(similar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0236597431380714,\n",
       " b\"From: Thomas Dachsel <GERTHD@mvs.sas.com>\\nSubject: BOOT PROBLEM with IDE controller\\nNntp-Posting-Host: sdcmvs.mvs.sas.com\\nOrganization: SAS Institute Inc.\\nLines: 25\\n\\nHi,\\nI've got a Multi I/O card (IDE controller + serial/parallel\\ninterface) and two floppy drives (5 1/4, 3 1/2) and a\\nQuantum ProDrive 80AT connected to it.\\nI was able to format the hard disk, but I could not boot from\\nit. I can boot from drive A: (which disk drive does not matter)\\nbut if I remove the disk from drive A and press the reset switch,\\nthe LED of drive A: continues to glow, and the hard disk is\\nnot accessed at all.\\nI guess this must be a problem of either the Multi I/o card\\nor floppy disk drive settings (jumper configuration?)\\nDoes someone have any hint what could be the reason for it.\\nPlease reply by email to GERTHD@MVS.SAS.COM\\nThanks,\\nThomas\\n+-------------------------------------------------------------------+\\n| Thomas Dachsel                                                    |\\n| Internet: GERTHD@MVS.SAS.COM                                      |\\n| Fidonet:  Thomas_Dachsel@camel.fido.de (2:247/40)                 |\\n| Subnet:   dachsel@rnivh.rni.sub.org (UUCP in Germany, now active) |\\n| Phone:    +49 6221 4150 (work), +49 6203 12274 (home)             |\\n| Fax:      +49 6221 415101                                         |\\n| Snail:    SAS Institute GmbH, P.O.Box 105307, D-W-6900 Heidelberg |\\n| Tagline:  One bad sector can ruin a whole day...                  |\\n+-------------------------------------------------------------------+\\n\")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最も類似度が高い文書を表示\n",
    "similar[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2895660283716477,\n",
       " b\"From: ksc@cbnewsk.cb.att.com (kenneth.s.cobler)\\nSubject: XFree86 and Esix 4.0.4\\nOrganization: AT&T\\nDistribution: na\\nKeywords: esix\\nLines: 39\\n\\nHello Netlanders:\\n\\n       I am a novice X user with a question for any Xgod.\\n\\n       My computer configuration with the X problem is as follows:\\n\\n       486DX50/256/16RAM  running Esix 4.0.4 \\n       Wangtek AT-style interface 250 M tape drive.\\n       I have loaded the Basic OS (which includes nsu) and\\n       inet utilities (tcp/ip).\\n       I ftp-ed the XFree86 (X11R5) binaries and installed properly.\\n \\n I can execute startx and run X-windows with no problems.\\n However, if I try to access the tape drive while in X, the\\n machine locks up instantly.  If I am out of X and access the\\n tape, the tape drive works fine.  Soon as I try to\\n startx again; the screen changes modes, but, the grey background\\n pattern does not come up and no xterm is forked.  I have to login\\n from another terminal and execute a shutdown to reset the system.\\n\\n I've contacted Esix about this problem.  They claim THEIR X-window X11R4\\n server (which I have) works with the Wangtek tape drive.  They also \\n claim I only need the nsu (network system utilities) to run X; I don't\\n need inet (tcp/ip).  My experience has been that I need BOTH to get\\n XFree86 to work.  I'm not too concerned about having to load both nsu and inet\\n packages to get X to work unless the inet package is causing my problem.\\n\\n I would like to get both X and my tape drive to co-exist on the same\\n system.  If you can shed any light on the problem, it would be appreciated.\\n \\n One colleague implied this might be a hardware conflict.  If this is true,\\n what direction should I look to resolve the conflict ?\\n\\n Thanks,\\n \\n Kenneth Cobler                ksc@ihlpv.att.com\\n AT&T Bell Laboratories\\n 263 Shuman Blvd.\\n Naperville, IL  60566\\n\")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 類似度が中間の文書を表示\n",
    "similar[int(len(similar)/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3881773610496,\n",
       " b'From: thorf@csa.bu.edu (Thor Farrish)\\nSubject: Maxtor drive geometry/jumpers\\nDistribution: usa\\nOrganization: Computer Science Department, Boston University, Boston, MA, USA\\nLines: 1\\n\\n\\n')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 類似度が最も低い文書を表示\n",
    "similar[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
